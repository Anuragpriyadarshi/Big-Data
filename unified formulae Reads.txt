you have data usdata.csv

Ensure first line of the file should be header of the dataframe

Read the data directly

Create the tempview 

Filter state='LA'

Show it

===============================================================================================
Solution
===============================================================================================
package sparkpack

import org.apache.spark._
import sys.process._
import org.apache.spark.SparkConf
import org.apache.spark.sql._
import org.apache.spark.sql.types._


object sparkobj {

case class schema(txnno:String, txndate:String, custno:String, amount:String, category:String, product:String,city:String, state:String, spendby:String)
def main(args:Array[String]):Unit=

{

		val conf = new SparkConf().setAppName("First").setMaster("local[*]")
				val sc = new SparkContext(conf)

				sc.setLogLevel("ERROR")
				val spark = SparkSession
				.builder()
				.getOrCreate()		

				import spark.implicits._

				val df=spark.read.format("csv").option("header","true").load("file:///c:/data/usdata.csv")

				df.show()
				df.createOrReplaceTempView("Anuragdf")
				val filterdf=spark.sql("select * from Anuragdf where state='LA'")
				filterdf.show()

}
}